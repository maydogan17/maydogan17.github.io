<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Murat Han Aydoğan</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta property="og:title" content="Murat Han Aydoğan Portfolio" />
    <meta property="og:type" content="website" />
    <meta
      property="og:description"
      content="A portfolio website to showcase my resume and projects."
    />
    <meta property="og:image" content="imgs/thumbnail.png" />
    <meta property="og:url" content="https://maydogan17.github.io/" />
    <meta name="twitter:card" content="summary_large_image" />
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css"
      rel="stylesheet"
      integrity="sha384-Zenh87qX5JnK2Jl0vWa8Ck2rdkQ2Bzep5IDxbcnCeuOxjzrPF/et3URy9Bv1WTRi"
      crossorigin="anonymous"
    />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.9.1/font/bootstrap-icons.css"
    />
    <link rel="stylesheet" href="css/index.css" />
  </head>
  <body>
    <header class="navbar navbar-expand sticky-bottom" id="home">
        <div class="container-fluid py-3">
          <a class="navbar-brand" href="#home"
            ><i class="bi bi-code h-100"></i
          ></a>
          <div class="navbar-nav">
            <a class="nav-link active" aria-current="page" href="index.html">Home</a>
            <a
              class="nav-link"
              href="https://github.com/maydogan17"
              target="_blank"
              ><i class="bi bi-github"></i
            ></a>
            <a
              class="nav-link"
              href="https://www.linkedin.com/in/maydogan17/"
              target="_blank"
              ><i class="bi bi-linkedin"></i
            ></a>
          </div>
        </div>
      </header>
      <div class="container mt-lg-5 mb-lg-5 pb-lg-5 pt-lg-5" id="title">
        <div class="row mt-5 pt-5">
          <div class="col-12 mb-2 pb-5">
            <h4 class="display-6">"Yeess!" "No-oh-oh..." Implicit Robot Task Information from Prosody in Human Verbal Feedback</h4>
            <br>
            <br>
            <div class="text-center">
              <img src="imgs/robot.gif" class="rounded">
          </div>
          </div>
        </div>
      </div>
      <div class="container-fluid pt-4 pb-4" id="authors_title">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <h2 class="display-6 mb-0">Authors</h2>
            </div>
          </div>
        </div>
      </div>
      <div class="container mt-5 mb-5 pt-5 pb-5" id="authors">
        <div class="row">
          <div class="col-sm-4">
            <p class="mb-0">Murat Han Aydoğan</p>
            <p class="mb-0">VU Amsterdam</p>
            <p class="mb-0">maydogan17@ku.edu.tr</p>
            <br>
            <br>
            <p class="mb-0">Taylor Kessler Faulkner</p>
            <p class="mb-0">University of Washington</p>
            <p class="mb-0">taylorkf@uw.edu</p>
          </div>
          <div class="col-sm-4">
            <p class="mb-0">Kenneth D Mitra</p>
            <p class="mb-0">University of Texas at Austin</p>
            <p class="mb-0">kennethmitra@utexas.edu</p>
            <br>
            <br>
            <p class="mb-0">Akanksha Saran</p>
            <p class="mb-0">Microsoft Research NYC</p>
            <p class="mb-0">akanksha.saran@microsoft.com</p>
          </div>
          <div class="col-sm-4">
            <p class="mb-0">Kush Desai</p>
            <p class="mb-0">University of Texas at Austin</p>
            <p class="mb-0">kushkdesai@utexas.edu</p>
            <br>
            <br>
            <p class="mb-0">Kim Baraka</p>
            <p class="mb-0">VU Amsterdam</p>
            <p class="mb-0">k.baraka@vu.nl</p>
          </div>
        </div>
      </div>
      <div class="container-fluid pt-4 pb-4" id="project_title">
        <div class="container">
          <div class="row">
            <div class="col-6">
              <h2 class="display-6 mb-0">Project</h2>
            </div>
            <div class="col-3 offset-md-3">
                <a href="https://drive.google.com/file/d/15y3ImaoqRoil371eReIC1TbwkzDRJX6o/view?usp=sharing" target="_blank" class="btn btn-dark" role="button">Download PDF</a>
            </div>
          </div>
        </div>
      </div>
      <div class="container mt-5 mb-5 pt-5 pb-5" id="project_content">
        <div class="row">
          <div class="col-12 col-lg-12" id="exp">
            <h2 class="display-6 pb-3">Executive Summary</h2>
            <ul>
              <li>
                <p class="mb-0"><b>Objective: </b>Explore prosody (speech patterns) as a teaching signal in robot learning from human feedback.</p>
              </li>
              <li>
                <p class="mb-0"><b>Methodology: </b>Mixed-participant Wizard-of-Oz study: one participant teaches; another controls a robot based on verbal feedback.</p>
              </li>
              <li>
                <p class="mb-0"><b>Key Insight: </b>Significant correlation found between speech patterns like pitch and energy, and robot learning features.</p>
              </li>
              <li>
                <p class="mb-0"><b>Previous Work: </b>Earlier studies emphasized words, not speech patterns, in robot learning.</p>
              </li>
              <li>
                <p class="mb-0"><b>Study Highlights: </b>
                  <ul>
                    <li>
                      Teachers used "yes/no" feedback, with speech patterns analyzed for learning insights.
                    </li>
                    <li>
                      Wizards controlled robots based on this feedback.
                    </li>
                  </ul>
                  </p>
              </li>
              <li>
                <p class="mb-0"><b>Technologies Used: </b>
                <ul>
                  <li>
                    Audio analysis with <code>Librosa</code> for loudness and energy measurements.
                  </li>
                  <li>
                    Google Cloud’s Speech-To-Text for transcriptions.
                  </li>
                  <li>
                    Python libraries used for data analysis are: <code>Pandas</code>, <code>Numpy</code>, <code>SciPy</code>, and <code>Matplotlib</code>.
                  </li>
                </ul>
                </p>
              </li>
              <li>
                <p class="mb-0"><b>Future Steps:</b>
                  <ul>
                    <li>
                      Develop models using prosody for improved robot learning.
                    </li>
                    <li>
                      Enrich human-robot teaching interfaces by incorporating speech patterns.
                    </li>
                  </ul>
                </p>
              </li>
              <li>
                <p class="mb-0"><b>Conclusion: </b>Speech patterns offer valuable information for enhancing robot learning from human interaction.</p>
              </li>
            </ul>
            <br>
            <h2 class="display-6 pb-3">Abstract</h2>
            <p class="mb-0">
                This paper presents preliminary evidence that prosody carries useful 
                task information in an interactive reinforcement learning setting with 
                verbal evaluative feedback from a human teacher. We developed a novel 
                mixed-participant Wizard-of-Oz study setup to collect audio data from 
                participants teaching a reinforcement learning agent in a grid world 
                navigation task where the agent was wizarded by another participant, 
                hence simulating prosody-sensitive agent learning. Our pilot study shows 
                that, for the participants tested in the teacher role, prosodic features 
                such as energy and pitch are statistically significantly correlated with 
                the advantage function, an underlying Markov Decision Process feature used 
                by RL algorithms. Results also suggest some level of individual differences 
                between different teachers. While further research is needed to develop 
                computational models of human teachers' prosody in different learning tasks, 
                our early results highlight the potential of tapping into implicit voice 
                signals to improve robot learning and human teaching efficiency.
            </p>
            <br>
          </div>
        </div>
      </div>
      <button
      type="button"
      class="btn btn-secondary btn-floating text-center"
      id="btn-back-to-top"
    >
      <i class="bi bi-arrow-up"></i>
    </button>
    <footer class="pt-5 pb-5">
      <div class="container">
        <div class="row">
          <div class="col-lg-3 col-12 text-center">
            <p>
              <i class="bi bi-envelope"></i>
              <a href="mailto: maydogan17@ku.edu.tr" target="_blank"
                >maydogan17@ku.edu.tr</a>
            </p>
          </div>
          <div class="col-lg-3 col-12 text-center">
            <p><i class="bi bi-telephone"></i> +90 505 260 64 17</p>
          </div>
          <div class="col-lg-3 col-12 text-center">
            <address>Yenimahalle, Ankara, Türkiye</address>
          </div>
          <div class="col-lg-3 col-12 text-center">
            <a href="https://twitter.com/murathanaydgn" target="_blank"
              ><i class="bi bi-twitter"></i> @murathanaydgn</a
            >
          </div>
        </div>
      </div>
    </footer>
    <script
      src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js"
      integrity="sha384-OERcA2EqjJCMA+/3y+gxIOqMEjwtxJY7qPCqsdltbNJuaOe923+mo//f6V8Qbsw3"
      crossorigin="anonymous"
    ></script>
    <script type="text/javascript" src="js/index.js"></script>
  </body>
</html>